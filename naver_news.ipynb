{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "import urllib.parse as par\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "client_id = \"2f1UivTJ6JgJILFj0JFp\"\n",
    "client_secret = \"UTrYqwSVy2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRequestUrl(url):\n",
    "    request=req.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    try:\n",
    "        response=req.urlopen(request)\n",
    "        if response.getcode()==200:\n",
    "            print(\"[%s] Url Request Success\" %datetime.datetime.now())\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" %(datetime.datetime.now(),url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNaverSearch(node, src_text, start, display):\n",
    "    base=f\"https://openapi.naver.com/v1/search/{node}\"\n",
    "    params=f\"?query={par.quote(src_text)}&start={start}&display={display}\"\n",
    "    url=base+params\n",
    "    resDecode=getRequestUrl(url)\n",
    "    if resDecode==None:\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(resDecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPostData(item, jsonResult, tuple_list, cnt):\n",
    "    title=item['title'].replace('&quot;','').replace('<b>','').replace('</b>','').replace('&lt;','').replace('&gt;','').replace('&amp;','')\n",
    "    description=item['description'].replace('&quot;','').replace('<b>','').replace('</b>','').replace('&lt;','').replace('&gt;','').replace('&amp;','')\n",
    "    link=item['link']\n",
    "    pDate=datetime.datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900')\n",
    "    pDate=pDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    tuple_list.append((title,description,link,pDate))\n",
    "    jsonResult.append({'cnt':cnt,'title':title,'description':description,'link':link,'pDate':pDate})\n",
    "    #print(title,pDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_db(tuple_list):\n",
    "    #db에 저장하기\n",
    "    import pymysql\n",
    "    conn=pymysql.connect(host='localhost',user='root',password='1234',db='sampledb',charset='utf8')\n",
    "    cur=conn.cursor()\n",
    "\n",
    "    sql='insert into news(title,description,link,pDate) values(%s,%s,%s,%s)'\n",
    "    cur.executemany(sql,tuple_list)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def save_csv(tuple_list):\n",
    "    #csv파일로 저장하기\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as par\n",
    "def main():\n",
    "    node='news'\n",
    "    src_text = par.quote(input(\"검색어를 입력하세요: \"))\n",
    "    cnt=0\n",
    "    tuple_list=[]\n",
    "    jsonResult=[]\n",
    "    jsonResponse=getNaverSearch(node, src_text, 1, 100) #노드, 검색어, start, display\n",
    "    #print(jsonResponse)\n",
    "    total=jsonResponse['total']\n",
    "\n",
    "    while((jsonResponse!=None) and (jsonResponse['display']!=0)):\n",
    "        for item in jsonResponse['items']:\n",
    "            cnt+=1\n",
    "            getPostData(item, jsonResult, tuple_list, cnt)\n",
    "\n",
    "        start=jsonResponse['start']+jsonResponse['display']\n",
    "        jsonResponse=getNaverSearch(node, src_text, start, 100)\n",
    "\n",
    "    print(\"전체 검색 : %d 건\" %cnt)\n",
    "    #print(jsonResult) json형태로 출력\n",
    "    with open(f'{src_text}_naver_{node}.json','w',encoding='utf-8') as f:\n",
    "        jsonFile=json.dumps(jsonResult, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "        f.write(jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-25 15:38:04.856781] Url Request Success\n",
      "[2025-03-25 15:38:05.090716] Url Request Success\n",
      "[2025-03-25 15:38:05.309526] Url Request Success\n",
      "[2025-03-25 15:38:05.542557] Url Request Success\n",
      "[2025-03-25 15:38:05.739838] Url Request Success\n",
      "[2025-03-25 15:38:05.971401] Url Request Success\n",
      "[2025-03-25 15:38:06.235176] Url Request Success\n",
      "[2025-03-25 15:38:06.508449] Url Request Success\n",
      "[2025-03-25 15:38:06.803710] Url Request Success\n",
      "[2025-03-25 15:38:07.085007] Url Request Success\n",
      "HTTP Error 400: Bad Request\n",
      "[2025-03-25 15:38:07.215287] Error for URL : https://openapi.naver.com/v1/search/news?query=%25EA%25B9%2580%25EC%2597%25B0%25EC%2595%2584&start=1001&display=100\n",
      "전체 검색 : 1000 건\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터랩에서 검색어 트렌드\n",
    "2024.01.01 ~ 2024.12.31\n",
    "연령별, 성별, 월별 검색어 트렌드를 수집하여, csv에 저장하는 코드를 작성하여 제출\n",
    "\n",
    "데이터 수집 과제 리스트\n",
    "- 알리딘 book 데이터 수집(정적크롤링)\n",
    "- 네이버 이미지 검색(동적 크롤링)\n",
    "- 스타벅스 매장(동적 크롤링)\n",
    "- 버스 노선별 버스정유장 도착 예정정보(공공데이터)\n",
    "- 네이버 데이터랩 검색어 트랜드 가져오기(데이터랩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as par\n",
    "import csv\n",
    "#네이버 api인증정보\n",
    " \n",
    "client_id = \"huZmgXF9dxPvAANBmCEL\"\n",
    "client_secret = \"ku3aqw8UZ2\"\n",
    "\n",
    "#요쳥 url 및 헤더 설정\n",
    "\n",
    "encText = par.parse.quote(\"\")\n",
    "url = \"https://openapi.naver.com/v1/datalab/search/?query\" + encText # JSON 결과\n",
    "request = par.request.Request(url) #request객체 생성\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = par.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "item_list=[]\n",
    "\n",
    "#요청할 기간 및 검색 조건 설정\n",
    "start_date = \"2024-01-01\"\n",
    "end_date = \"2024-12-31\"\n",
    "group_names = [\"남성_10대\", \"남성_20대\", \"남성_30대\", \"남성_40대\", \"남성_50대\", \"여성_10대\", \"여성_20대\", \"여성_30대\", \"여성_40대\", \"여성_50대\"]\n",
    "ages = [\"10\", \"20\", \"30\", \"40\", \"50\"]\n",
    "genders = [\"m\", \"f\"]\n",
    "\n",
    "#CSV 파일 저장 준비\n",
    "csv_filename = \"naver_trends_2024.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Date\", \"Gender\", \"Age\", \"Keyword\", \"Ratio\"])\n",
    "\n",
    "\n",
    "#연령별, 성별 검색 트렌드 데이터 요청\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
